{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3230707f",
   "metadata": {},
   "source": [
    "# Keras 임베딩 계층 사용 실습\n",
    "\n",
    "이 노트북은 아래 문서에 실려 있는 예제를 실습하면서 작성한 것입니다.\n",
    "\n",
    "* [How to Use Word Embedding Layers for Deep Learning with Keras\n",
    "](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18fba1",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "학업 성취에 대한 대한 긍정, 부정 평가와 같이 이진 분류 문제를 다룰 때 사용할 수 있는 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf02685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577da05",
   "metadata": {},
   "source": [
    "## 학습을 통해 임베딩 구하기\n",
    "\n",
    "### 단어 인코딩\n",
    "\n",
    "단어를 정수로 인코딩합니다. 여기서 사용하는 `one_hot()` 함수는 단어의 해시값을 구해서 정수로 인코딩하는 방식이어서 서로 다른 단어이지만 동일한 값으로 인코딩되는 경우가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b03a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 24], [36, 19], [3, 35], [45, 19], [33], [48], [3, 35], [2, 36], [3, 19], [48, 15, 24, 12]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fd1b1",
   "metadata": {},
   "source": [
    "위의 결과를 보면 `one_hot()` 함수를 사용하여 단어를 인코딩할 때 아래와 같이 충돌이 발생한다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb4b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 12]\n",
      "[36, 3, 36]\n",
      "[2, 15]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot('Well better', vocab_size))\n",
    "print(one_hot('Good Great good', vocab_size))\n",
    "print(one_hot('not have', vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94528f",
   "metadata": {},
   "source": [
    "입력 데이터의 길이를 모두 동일하게 맞추기 위하여 `pad_sequences()` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20d3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47 24  0  0]\n",
      " [36 19  0  0]\n",
      " [ 3 35  0  0]\n",
      " [45 19  0  0]\n",
      " [33  0  0  0]\n",
      " [48  0  0  0]\n",
      " [ 3 35  0  0]\n",
      " [ 2 36  0  0]\n",
      " [ 3 19  0  0]\n",
      " [48 15 24 12]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac88dd",
   "metadata": {},
   "source": [
    "### 모델 구성\n",
    "\n",
    "`Embedding` 계층의 출력은 2차원이고 `Dense` 계층의 입력은 1차원이므로 이 둘을 이어주기 위하여 `Flatten` 계층을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e6fd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ce09c",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08da2c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.000001\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65647d4c",
   "metadata": {},
   "source": [
    "## 사전 학습된 GloVe 임베딩 사용하기\n",
    "\n",
    "### 단어 인코딩\n",
    "\n",
    "단어를 정수로 인코딩합니다. 이번에는 `Tokenizer`를 사용하여 인코딩해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e0a980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'work': 1, 'done': 2, 'good': 3, 'effort': 4, 'poor': 5, 'well': 6, 'great': 7, 'nice': 8, 'excellent': 9, 'weak': 10, 'not': 11, 'could': 12, 'have': 13, 'better': 14}\n",
      "vocab_size: 15\n",
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(t.word_index)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7cbc2",
   "metadata": {},
   "source": [
    "입력 데이터의 길이를 모두 동일하게 맞추기 위하여 pad_sequences() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44036065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36414891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "\n",
    "with open('C:\\DevData\\GloVe\\glove.6B.50d.txt', mode='r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        if word in t.word_index:\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "print(f'Loaded {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5ec951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.13589978e-01  1.96950004e-01 -5.19439995e-01 -8.62179995e-01\n",
      "   1.54940002e-02  1.09729998e-01 -8.02929997e-01 -3.33609998e-01\n",
      "  -1.61189993e-04  1.01889996e-02  4.67340015e-02  4.67510015e-01\n",
      "  -4.74750012e-01  1.10380001e-01  3.93269986e-01 -4.36520010e-01\n",
      "   3.99839997e-01  2.71090001e-01  4.26499993e-01 -6.06400013e-01\n",
      "   8.11450005e-01  4.56299990e-01 -1.27260000e-01 -2.24739999e-01\n",
      "   6.40709996e-01 -1.27670002e+00 -7.22310007e-01 -6.95900023e-01\n",
      "   2.80450005e-02 -2.30719998e-01  3.79959989e+00 -1.26249999e-01\n",
      "  -4.79669988e-01 -9.99719977e-01 -2.19760001e-01  5.05649984e-01\n",
      "   2.59530004e-02  8.05140018e-01  1.99290007e-01  2.87959993e-01\n",
      "  -1.59150004e-01 -3.04380000e-01  1.60249993e-01 -1.82899997e-01\n",
      "  -3.85629982e-02 -1.76190004e-01  2.70409994e-02  4.68420014e-02\n",
      "  -6.28970027e-01  3.57259989e-01]\n",
      " [ 3.30760002e-01 -4.38699991e-01 -3.21630001e-01 -4.93099988e-01\n",
      "   1.02540001e-01 -2.74210004e-03 -5.17199993e-01  2.43360009e-02\n",
      "  -1.28160000e-01  1.43490002e-01 -1.66909993e-01  5.61209977e-01\n",
      "  -5.62409997e-01 -4.09720019e-02  7.50000000e-01  2.30839998e-01\n",
      "   5.32040000e-01 -4.09730002e-02  2.68920004e-01 -6.92380011e-01\n",
      "   2.78829992e-01  3.79110008e-01  5.63899994e-01 -3.81500006e-01\n",
      "   7.21319973e-01 -1.35619998e+00 -8.17170024e-01 -5.48419990e-02\n",
      "   5.73329985e-01 -8.54889989e-01  3.18889999e+00  1.99180007e-01\n",
      "  -4.21200007e-01 -9.04269993e-01 -1.95209995e-01  3.01109999e-01\n",
      "   4.67559993e-01  8.21300030e-01  6.05520010e-02 -1.61430001e-01\n",
      "  -2.66680002e-01 -1.76599994e-01  1.58200003e-02  2.55279988e-01\n",
      "  -9.67390016e-02 -9.72819999e-02 -8.44829977e-02  3.33119988e-01\n",
      "  -2.22519994e-01  7.44570017e-01]\n",
      " [-3.55859995e-01  5.21300018e-01 -6.10700011e-01 -3.01310003e-01\n",
      "   9.48620021e-01 -3.15389991e-01 -5.98309994e-01  1.21880002e-01\n",
      "  -3.19430009e-02  5.56949973e-01 -1.06210001e-01  6.33989990e-01\n",
      "  -4.73399997e-01 -7.58949965e-02  3.82470012e-01  8.15690011e-02\n",
      "   8.22139978e-01  2.22200006e-01 -8.37639999e-03 -7.66200006e-01\n",
      "  -5.62529981e-01  6.17590010e-01  2.02920005e-01 -4.85979989e-02\n",
      "   8.78149986e-01 -1.65489995e+00 -7.74179995e-01  1.54349998e-01\n",
      "   9.48230028e-01 -3.95200014e-01  3.73020005e+00  8.28549981e-01\n",
      "  -1.41039997e-01  1.63950007e-02  2.11150005e-01 -3.60849984e-02\n",
      "  -1.55870005e-01  8.65830004e-01  2.63090014e-01 -7.10150003e-01\n",
      "  -3.67700011e-02  1.82819995e-03 -1.77039996e-01  2.70319998e-01\n",
      "   1.10260002e-01  1.41330004e-01 -5.73219992e-02  2.72069991e-01\n",
      "   3.13050002e-01  9.27709997e-01]\n",
      " [ 7.09020019e-01 -6.08609974e-01  2.64470011e-01 -5.45560002e-01\n",
      "  -8.00559968e-02  1.54640004e-01 -5.39529979e-01  3.18520010e-01\n",
      "   7.45949984e-01  4.50019985e-01 -6.79440022e-01 -9.34159979e-02\n",
      "  -6.25569999e-01  1.66010007e-01 -3.48589987e-01 -5.37109971e-01\n",
      "   1.00380003e+00 -5.46079993e-01  1.47909999e-01 -3.78930002e-01\n",
      "   3.24259996e-01  4.77820002e-02 -7.14290023e-01 -1.00329995e+00\n",
      "   2.08430007e-01 -1.77559996e+00  1.24679998e-01 -6.15610003e-01\n",
      "   4.94029999e-01 -6.83329999e-02  3.19689989e+00  5.07049978e-01\n",
      "  -1.09840000e+00 -6.69990003e-01 -4.27170008e-01  3.33139986e-01\n",
      "  -5.24100006e-01  2.09270000e-01 -2.67309994e-01 -9.02930021e-01\n",
      "  -4.72389996e-01 -2.15179995e-01 -1.61080003e-01 -5.66910028e-01\n",
      "  -1.50499996e-02 -2.80930009e-02  1.96119994e-01  6.29209995e-01\n",
      "  -2.38749996e-01  1.72600001e-01]\n",
      " [-5.38190007e-01 -4.07880008e-01 -1.96300000e-01 -8.08210015e-01\n",
      "   7.71450028e-02  2.57849991e-02 -5.04819989e-01 -6.88870028e-02\n",
      "   1.36280000e-01  2.86190003e-01  8.21499974e-02 -2.68860012e-01\n",
      "   3.93500000e-01 -9.48450029e-01  2.16120005e-01 -1.94330007e-01\n",
      "   1.75880000e-01 -2.83730000e-01  5.34959972e-01 -2.61350006e-01\n",
      "  -5.45120001e-01  4.91430014e-01 -3.27520013e-01 -4.06620018e-02\n",
      "   4.16889995e-01 -1.02610004e+00 -5.67520000e-02 -4.31340009e-01\n",
      "   5.06919980e-01  6.98109984e-01  3.54509997e+00  7.90690005e-01\n",
      "   7.54549980e-01 -4.28250015e-01  7.56919980e-02  3.54660004e-01\n",
      "  -3.89970005e-01 -2.14450005e-02  5.58510005e-01 -5.66009998e-01\n",
      "  -7.96440005e-01  3.87879983e-02  7.94690013e-01  3.25060010e-01\n",
      "   2.09749997e-01  2.02480003e-01 -6.31810009e-01  5.21799996e-02\n",
      "   1.07309997e+00  3.56290005e-02]\n",
      " [ 2.76910007e-01  2.87449986e-01 -2.99349993e-01 -1.99640006e-01\n",
      "   1.29559994e-01  1.55550003e-01 -6.45219982e-01 -3.40900004e-01\n",
      "  -1.18330002e-01  1.57979995e-01  1.39689997e-01  2.48720005e-01\n",
      "  -1.59009993e-01 -3.34389992e-02  1.18950002e-01  7.65350014e-02\n",
      "   4.52630013e-01  2.64939994e-01 -1.91569999e-01 -5.67680001e-01\n",
      "   2.92860009e-02  2.17449993e-01  4.34060007e-01  1.49810001e-01\n",
      "   7.57739991e-02 -1.44529998e+00 -5.83940029e-01 -4.60629985e-02\n",
      "   6.62140027e-02 -2.64169991e-01  3.96499991e+00  2.51960009e-01\n",
      "   2.48549998e-01 -5.05240023e-01  2.58060008e-01  2.86830008e-01\n",
      "  -1.79940000e-01  6.28849983e-01 -1.20399997e-01 -4.21429984e-02\n",
      "  -4.49110009e-02  1.85609996e-01  1.62660003e-01 -2.61269999e-03\n",
      "   1.30830005e-01  2.01790005e-01 -2.96669990e-01 -9.48200002e-02\n",
      "  -2.12500006e-01  2.20740009e-02]\n",
      " [-2.65670009e-02  1.33570004e+00 -1.02800000e+00 -3.72900009e-01\n",
      "   5.20120025e-01 -1.26990005e-01 -3.54330003e-01  3.78239989e-01\n",
      "  -2.97160000e-01  9.38939974e-02 -3.41220014e-02  9.29610014e-01\n",
      "  -1.40230000e-01 -6.32990003e-01  2.08010003e-02 -2.15330005e-01\n",
      "   9.69229996e-01  4.76539999e-01 -1.00390005e+00 -2.40130007e-01\n",
      "  -3.63249987e-01 -4.75700013e-03 -5.14800012e-01 -4.62599993e-01\n",
      "   1.24469995e+00 -1.83159995e+00 -1.55809999e+00 -3.74650002e-01\n",
      "   5.33620000e-01  2.08829999e-01  3.22090006e+00  6.45489991e-01\n",
      "   3.74379992e-01 -1.76569998e-01 -2.41640005e-02  3.37859988e-01\n",
      "  -4.19000000e-01  4.00810003e-01 -1.14490002e-01  5.12319990e-02\n",
      "  -1.52050003e-01  2.98550010e-01 -4.40519989e-01  1.10890001e-01\n",
      "  -2.46329993e-01  6.62509978e-01 -2.69490004e-01 -4.96580005e-01\n",
      "  -4.16180015e-01 -2.54900008e-01]\n",
      " [ 2.01890007e-01  8.06060016e-01 -1.12810004e+00 -5.95929980e-01\n",
      "   5.27559996e-01 -4.76900011e-01 -5.26400030e-01  1.45260006e-01\n",
      "  -8.60870004e-01  5.61990023e-01 -4.37079996e-01 -1.65859997e-01\n",
      "  -2.33280003e-01 -2.17260003e-01  5.21139979e-01  6.23070002e-02\n",
      "   5.51150024e-01 -1.80020005e-01 -3.29829991e-01 -9.44339991e-01\n",
      "  -6.20190024e-01  7.87639976e-01 -3.61330003e-01  6.85800016e-01\n",
      "   3.79099995e-01 -8.77439976e-01 -7.67920017e-01  1.28849995e+00\n",
      "   1.14199996e+00 -7.34889984e-01  2.39319992e+00  1.09669995e+00\n",
      "  -4.86860007e-01  5.28400004e-01  3.92699987e-01 -5.64269982e-02\n",
      "   2.96319991e-01  1.07980001e+00  4.51570004e-01 -9.81149971e-01\n",
      "   1.00370002e+00  1.56340003e-01  2.25840006e-02 -1.48320004e-01\n",
      "  -9.29329991e-02  3.36910009e-01  4.21710014e-01 -2.16419995e-01\n",
      "   1.01390004e+00  1.05350006e+00]\n",
      " [-4.04309988e-01  7.80019999e-01 -6.75379992e-01 -9.71489996e-02\n",
      "   5.42420030e-01 -5.12830019e-01 -4.77580011e-01 -1.14289999e-01\n",
      "   5.51940024e-01  4.95299995e-01  2.56810009e-01  4.15160000e-01\n",
      "   3.82230014e-01  3.39360014e-02 -5.19810021e-01 -5.75200021e-01\n",
      "   5.09750009e-01  4.40290004e-01 -1.68850005e-01 -7.56869972e-01\n",
      "  -3.67469996e-01  3.72689992e-01 -8.66999999e-02 -3.10570002e-01\n",
      "   7.03400016e-01 -4.68490005e-01 -4.78450000e-01  1.57940000e-01\n",
      "   2.39690006e-01  1.61039993e-01  2.76320004e+00  3.33810002e-01\n",
      "   4.79530007e-01 -3.73100013e-01  7.10950017e-01  6.87900007e-01\n",
      "   6.73990026e-02  1.41770005e+00 -3.56299996e-01 -4.81590003e-01\n",
      "   5.32809973e-01 -7.45930001e-02  1.60280000e-02  2.33709998e-02\n",
      "  -2.95299999e-02 -1.24629997e-01  1.25009999e-01  7.22549975e-01\n",
      "   4.75899994e-01  7.95140028e-01]\n",
      " [-2.62410015e-01 -1.11029994e+00  5.02709985e-01 -4.30519998e-01\n",
      "   3.74680012e-01 -3.05500001e-01  3.67080003e-01  2.59380013e-01\n",
      "  -1.69929996e-01  5.42450011e-01  6.39190018e-01  1.13470003e-01\n",
      "  -3.91900003e-01  3.15210015e-01 -4.29010004e-01  4.99769986e-01\n",
      "  -2.37599999e-01 -7.93070018e-01  3.44940007e-01 -4.78769988e-01\n",
      "  -5.19450009e-01 -5.06649971e-01  5.77009991e-02 -3.17970008e-01\n",
      "  -8.01339969e-02 -1.02890003e+00 -1.50700003e-01  5.09440005e-01\n",
      "   6.07150018e-01  1.30490005e+00  3.25749993e+00  1.18490003e-01\n",
      "   1.50569999e+00 -3.66490006e-01 -1.77259997e-01 -2.09309995e-01\n",
      "  -5.95269978e-01 -2.58889999e-02 -2.96499997e-01 -1.13870001e+00\n",
      "  -5.29990017e-01  6.72859997e-02  9.49539989e-02  4.97220010e-02\n",
      "   5.13230026e-01 -1.11939996e-01 -7.11099990e-03  2.37749994e-01\n",
      "   6.88740015e-01  1.38730004e-01]\n",
      " [ 5.50249994e-01 -2.49420002e-01 -9.38599987e-04 -2.63999999e-01\n",
      "   5.93200028e-01  2.79500008e-01 -2.56660014e-01  9.30759981e-02\n",
      "  -3.62879992e-01  9.07759964e-02  2.84090012e-01  7.13370025e-01\n",
      "  -4.75100011e-01 -2.44130000e-01  8.84239972e-01  8.91089976e-01\n",
      "   4.30090010e-01 -2.73299992e-01  1.12760000e-01 -8.16649973e-01\n",
      "  -4.12719995e-01  1.77540004e-01  6.19419992e-01  1.04659997e-01\n",
      "   3.33270013e-01 -2.31250000e+00 -5.23710012e-01 -2.18979996e-02\n",
      "   5.38010001e-01 -5.06150007e-01  3.86829996e+00  1.66419998e-01\n",
      "  -7.19810009e-01 -7.47280002e-01  1.16310000e-01 -3.75849992e-01\n",
      "   5.55199981e-01  1.26750007e-01 -2.26420000e-01 -1.01750001e-01\n",
      "  -3.54550004e-01  1.23480000e-01  1.65319994e-01  7.04200029e-01\n",
      "  -8.02310035e-02 -6.84060007e-02 -6.76259995e-01  3.37630004e-01\n",
      "   5.01389988e-02  3.34650010e-01]\n",
      " [ 9.07540023e-01 -3.83219987e-01  6.76479995e-01 -2.02219993e-01\n",
      "   1.51559994e-01  1.36270002e-01 -4.88130003e-01  4.82230008e-01\n",
      "  -9.57150012e-02  1.83060005e-01  2.70069987e-01  4.14150000e-01\n",
      "  -4.89329994e-01 -7.60049978e-03  7.96620011e-01  1.09889996e+00\n",
      "   5.38020015e-01 -5.44679999e-01 -1.60630003e-01 -9.83479977e-01\n",
      "  -1.91880003e-01 -2.14399993e-01  1.99589998e-01 -3.13410014e-01\n",
      "   2.41009995e-01 -2.26620007e+00 -2.59259999e-01 -1.08980000e-01\n",
      "   6.61769986e-01 -4.81040001e-01  3.62980008e+00  4.53969985e-01\n",
      "  -6.44840002e-01 -5.22440016e-01  4.29220013e-02 -1.66050002e-01\n",
      "   9.71020013e-02  4.48359996e-02  2.03889996e-01 -4.63220000e-01\n",
      "  -4.64340001e-01  3.23940009e-01  2.59840012e-01  4.08490002e-01\n",
      "   2.03510001e-01  5.87220006e-02 -1.64079994e-01  2.06719995e-01\n",
      "  -1.84400007e-01  7.11470023e-02]\n",
      " [ 9.49109972e-01 -3.49680007e-01  4.81249988e-01 -1.93059996e-01\n",
      "  -8.83840024e-03  2.81819999e-01 -9.61300015e-01 -1.35810003e-01\n",
      "  -4.30830002e-01 -9.29329991e-02  1.56890005e-01  5.95850013e-02\n",
      "  -4.96349990e-01 -1.74140006e-01  7.56609976e-01  4.92100000e-01\n",
      "   2.17730001e-01 -2.27779999e-01 -1.36859998e-01 -9.05889988e-01\n",
      "  -4.87809986e-01  1.99190006e-01  9.14470017e-01 -1.62029997e-01\n",
      "  -2.06450000e-01 -1.73119998e+00 -4.76220012e-01 -4.85399999e-02\n",
      "  -1.40269995e-01 -4.58279997e-01  4.03259993e+00  6.05199993e-01\n",
      "   1.04479998e-01 -7.36100018e-01  2.48500004e-01 -3.34610008e-02\n",
      "  -1.33949995e-01  5.27819991e-02 -2.72680014e-01  7.98249990e-02\n",
      "  -8.01270008e-01  3.08310002e-01  4.35669988e-01  8.87470007e-01\n",
      "   2.98159987e-01 -2.46500000e-02 -9.50749993e-01  3.62329990e-01\n",
      "  -7.25120008e-01 -6.08900011e-01]\n",
      " [-1.20899998e-01 -1.68210000e-01  2.40989998e-01 -3.02870005e-01\n",
      "   4.35779989e-01 -3.83670002e-01 -5.52030027e-01 -2.86810011e-01\n",
      "  -1.00919999e-01  4.77690011e-01  2.89689988e-01  2.95489997e-01\n",
      "  -4.40739989e-01 -1.34939998e-01  2.60219991e-01  4.53709990e-01\n",
      "   5.37490010e-01  6.12200014e-02  2.43660003e-01 -8.77610028e-01\n",
      "  -5.62409997e-01  2.49270007e-01  1.79409996e-01 -1.69430003e-02\n",
      "   5.79739988e-01 -1.35459995e+00 -5.31610012e-01 -2.64510006e-01\n",
      "   6.82110012e-01 -3.04820001e-01  3.79430008e+00  9.63259995e-01\n",
      "  -7.38959983e-02 -4.10320014e-01  2.44780004e-01 -1.45789996e-01\n",
      "  -8.67889971e-02  9.95000005e-01  4.99279983e-02 -6.03020012e-01\n",
      "  -3.65850002e-01 -1.01140000e-01  4.04229999e-01  2.59510010e-01\n",
      "   8.79269987e-02  6.19600005e-02  7.52660036e-02  1.27550006e-01\n",
      "   6.64609969e-02  1.11629999e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f3c81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 4, 50)             750       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 201\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4af9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3997 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3965 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3934 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3903 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3873 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3843 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3813 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3784 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3755 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3726 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3698 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3670 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3643 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3616 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3589 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3563 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3537 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3511 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3485 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3460 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3435 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3411 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3362 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3338 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3315 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3292 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3269 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3246 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3223 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3201 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3179 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3157 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3136 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3115 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3093 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3073 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3052 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3031 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3011 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2991 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2971 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2952 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2913 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2894 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2857 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2838 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2820 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb5f3e02b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a459676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb9506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
